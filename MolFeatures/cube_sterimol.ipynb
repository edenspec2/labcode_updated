{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\edens\\Documents\\GitHub\\LabCode\\MolFeatures\\cube_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_0(x):\n",
    "    \"\"\"Count the number of leading zeros in a pandas Series before the first non-zero entry.\"\"\"\n",
    "    return (x.cumsum() == 0).sum()\n",
    "\n",
    "def get_transfomed_plane_for_sterimol(plane,degree):\n",
    "    \"\"\"\n",
    "    a function that gets a plane and rotates it by a given degree\n",
    "    in the case of sterimol the plane is the x,z plane.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    plane : np.array\n",
    "        [x,z] plane of the molecule coordinates.\n",
    "        example:\n",
    "            [-0.6868 -0.4964]\n",
    "    degree : float\n",
    "    \"\"\"\n",
    "    # print(degree,plane)\n",
    "    cos_deg=np.cos(degree*(np.pi/180))\n",
    "    sin_deg=np.sin(degree*(np.pi/180))\n",
    "    rot_matrix=np.array([[cos_deg,-1*sin_deg],[sin_deg,cos_deg]])\n",
    "    transformed_plane=np.vstack([np.matmul(rot_matrix,row) for row in plane]).round(3)\n",
    "    return transformed_plane\n",
    "\n",
    "def calc_B1(transformed_plane,avs,edited_coordinates_df,column_index):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    transformed_plane : np.array\n",
    "        [x,z] plane of the molecule coordinates.\n",
    "        example:\n",
    "            [-0.6868 -0.4964]\n",
    "            [-0.7384 -0.5135]\n",
    "            [-0.3759 -0.271 ]\n",
    "            [-1.1046 -0.8966]\n",
    "            [ 0.6763  0.5885]\n",
    "    avs : list\n",
    "        the max & min of the [x,z] columns from the transformed_plane.\n",
    "        example:[0.6763, -1.1046, 0.5885, -0.8966\n",
    "                 ]\n",
    "    edited_coordinates_df : TYPE\n",
    "        DESCRIPTION.\n",
    "    column_index : int\n",
    "        0 or 1 depending- being used for transformed plane.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## get the index of the min value in the column compared to the avs.min\n",
    "    idx=np.where(np.isclose(np.abs(transformed_plane[:,column_index]),(avs.min()).round(4)))[0][0]\n",
    "    if transformed_plane[idx,column_index]<0:\n",
    "        new_idx=np.where(np.isclose(transformed_plane[:,column_index],transformed_plane[:,column_index].min()))[0][0]\n",
    "        bool_list=np.logical_and(transformed_plane[:,column_index]>=transformed_plane[new_idx,column_index],\n",
    "                                 transformed_plane[:,column_index]<=transformed_plane[new_idx,column_index]+1)\n",
    "        \n",
    "        transformed_plane[:,column_index]=-transformed_plane[:,column_index]\n",
    "    else:\n",
    "        bool_list=np.logical_and(transformed_plane[:,column_index]>=transformed_plane[idx,column_index]-1,\n",
    "                                 transformed_plane[:,column_index]<=transformed_plane[idx,column_index])\n",
    "        \n",
    "    against,against_loc=[],[]\n",
    "    B1,B1_loc=[],[]\n",
    "    for i in range(1,transformed_plane.shape[0]): \n",
    "        if bool_list[i]:\n",
    "            against.append(np.array(transformed_plane[i,column_index]+edited_coordinates_df['radius'].iloc[i]))\n",
    "            against_loc.append(edited_coordinates_df['L'].iloc[i])\n",
    "        if len(against)>0:\n",
    "            B1.append(max(against))\n",
    "            B1_loc.append(against_loc[against.index(max(against))])\n",
    "            \n",
    "        else:\n",
    "            B1.append(np.abs(transformed_plane[idx,column_index]+edited_coordinates_df['radius'].iloc[idx]))\n",
    "            B1_loc.append(edited_coordinates_df['radius'].iloc[idx])\n",
    "            \n",
    "    # print(f'B1: {B1}, B1_loc: {B1_loc}')      \n",
    "    return [B1,B1_loc]\n",
    "\n",
    "def b1s_for_loop_function(extended_df, b1s, b1s_loc, degree_list, plane):\n",
    "    \"\"\"\n",
    "    a function that gets a plane transform it and calculate the b1s for each degree.\n",
    "    checks if the plane is in the x or z axis and calculates the b1s accordingly.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    extended_df : pd.DataFrame\n",
    "    b1s : list\n",
    "    b1s_loc : list\n",
    "    degree_list : list\n",
    "    plane : np.array\n",
    "    \"\"\"\n",
    "    degree=[]\n",
    "    for degree in degree_list:\n",
    "        transformed_plane=get_transfomed_plane_for_sterimol(plane, degree)\n",
    "        \n",
    "        avs=np.abs([max(transformed_plane[:,0]),min(transformed_plane[:,0]), \n",
    "                    max(transformed_plane[:,1]),min(transformed_plane[:,1])])\n",
    "        \n",
    "        if min(avs) == 0:\n",
    "            min_avs_indices = np.where(avs == min(avs))[0]\n",
    "            if any(index in [0, 1] for index in min_avs_indices):\n",
    "                tc = np.round(transformed_plane, 1)\n",
    "                B1 = max(extended_df['radius'].iloc[np.where(tc[:, 0] == 0)])\n",
    "                B1_loc = extended_df['L'].iloc[np.argmax(extended_df['radius'].iloc[np.where(tc[:, 0] == 0)])]\n",
    "                b1s.append(B1)\n",
    "                b1s_loc.append(B1_loc)\n",
    "                continue  # Skip the rest of the loop\n",
    "\n",
    "            elif any(index in [2, 3] for index in min_avs_indices):\n",
    "                tc = np.round(transformed_plane, 1)\n",
    "                B1 = max(extended_df['radius'].iloc[np.where(tc[:, 1] == 0)])\n",
    "                B1_loc = extended_df['L'].iloc[np.argmax(extended_df['radius'].iloc[np.where(tc[:, 1] == 0)])]\n",
    "                b1s.append(B1)\n",
    "                b1s_loc.append(B1_loc)\n",
    "                continue\n",
    "\n",
    "        if np.where(avs==avs.min())[0][0] in [0,1]:\n",
    "            B1,B1_loc=calc_B1(transformed_plane,avs,extended_df,0)\n",
    "            \n",
    "  \n",
    "        elif np.where(avs==avs.min())[0][0] in [2,3]:\n",
    "            B1,B1_loc=calc_B1(transformed_plane,avs,extended_df,1)\n",
    "             \n",
    "        \n",
    "        b1s.append(np.unique(np.vstack(B1)).max())####check\n",
    "        b1s_loc.append(np.unique(np.vstack(B1_loc)).max())\n",
    "\n",
    "def get_b1s_list(extended_df, scans=90//5):\n",
    "    \n",
    "    b1s,b1s_loc=[],[]\n",
    "    scans=scans\n",
    "    degree_list=list(range(18,108,scans))\n",
    "    plane=np.array(extended_df[['x','z']].astype(float))\n",
    "    b1s_for_loop_function(extended_df, b1s, b1s_loc, degree_list, plane)\n",
    "    \n",
    "    if b1s:\n",
    "        try:\n",
    "            back_ang=degree_list[np.where(b1s==min(b1s))[0][0]]-scans   \n",
    "            front_ang=degree_list[np.where(b1s==min(b1s))[0][0]]+scans\n",
    "            degree_list=range(back_ang,front_ang+1)\n",
    "        except:\n",
    "            print(np.where(np.isclose(b1s, min(b1s), atol=1e-8)))\n",
    "            back_ang=degree_list[np.where(np.isclose(b1s, min(b1s), atol=1e-8))[0][0]]-scans\n",
    "            front_ang=degree_list[np.where(np.isclose(b1s, min(b1s), atol=1e-8))[0][0]]+scans\n",
    "            degree_list=range(back_ang,front_ang+1)\n",
    "    else:\n",
    "        print('no b1s found')\n",
    "        return [np.array(b1s),np.array(b1s_loc)]\n",
    "    # print(f'specific degree list: {degree_list}')\n",
    "    b1s_for_loop_function(extended_df, b1s, b1s_loc, degree_list, plane)\n",
    "    # print(f'b1 arrays: {[np.array(b1s),np.array(b1s_loc)]}')\n",
    "    return [np.array(b1s),np.array(b1s_loc)]\n",
    "\n",
    "def get_molecule_connections(bonds_df,source,direction):\n",
    "    graph=ig.Graph.DataFrame(edges=bonds_df,directed=True)\n",
    "    paths=graph.get_all_simple_paths(v=source,mode='all')\n",
    "    with_direction=[path for path in paths if (direction in path)]\n",
    "    longest_path=np.unique(help_functions.flatten_list(with_direction))\n",
    "    return longest_path\n",
    "\n",
    "\n",
    "from scipy.special import cbrt\n",
    "\n",
    "def calc_angle(p1, p2, degrees: bool=False) -> float: ###works, name in R: 'angle' , radians\n",
    "    dot_product=np.dot(p1, p2)\n",
    "    norm_p1=np.linalg.norm(p1)\n",
    "    norm_p2=np.linalg.norm(p2)\n",
    "    thetha=np.arccos(dot_product/(norm_p1*norm_p2))\n",
    "    if degrees:\n",
    "        thetha=np.degrees(thetha)   \n",
    "    return thetha\n",
    "\n",
    "def vec_organizer(block, density, blocks, x_steps, y_steps, z_steps):\n",
    "    \n",
    "    start_index = blocks[block] \n",
    " \n",
    "    end_index = start_index + int(np.ceil(z_steps / 6)) -1\n",
    "    # end_index = min(end_index, density.shape[0] - 1)  # Ensure not exceeding bounds\n",
    "\n",
    "    # Selecting and transposing the block of data\n",
    "    vec = density.iloc[start_index:end_index + 1].values.flatten()\n",
    "    \n",
    "    # Print vector for debugging\n",
    "    # print(vec)\n",
    "\n",
    "    # Calculate the required vector length\n",
    "    target_length = int(np.ceil(cbrt(x_steps * y_steps * z_steps)))-1\n",
    "    \n",
    "    # Append zeros if the vector is shorter than the required length\n",
    "    if len(vec) < target_length:\n",
    "        vec = np.append(vec, np.zeros(target_length - len(vec)))\n",
    "    # print(vec)\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def pt_space_block(non_zero,x_blocks):\n",
    "    # x_blocks is the list of dataframes\n",
    "    # x_block_index is the index for the dataframe to process\n",
    "    df = x_blocks[non_zero]\n",
    "    \n",
    "    # Get indices of non-zero elements, np.argwhere returns a 2D array of indices\n",
    "    non_zero_indices = np.argwhere(df.to_numpy() != 0)\n",
    "    # Create a DataFrame from non-zero indices\n",
    "    non_zero_df = pd.DataFrame(non_zero_indices, columns=['Row', 'Column'])\n",
    "    ## rearrage the columns by the order of Column\n",
    "    \n",
    "    # Concatenate original block with its non-zero indices\n",
    "    non_zero=pd.DataFrame([non_zero]*len(non_zero_df))\n",
    "    return pd.concat([non_zero, non_zero_df], axis=1).sort_values(by='Column')\n",
    "\n",
    "def pt_space_block_binder(non_zero,x_blocks):\n",
    "    # Apply pt_space_block to each DataFrame in the list and concatenate them\n",
    "    \n",
    "    results = [pt_space_block(non_zero[i], x_blocks) for i in range(len(non_zero))]\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "\n",
    "def dens_to_pt(point, dense_points, x_origin, y_origin, z_origin, x_size, y_size, z_size):\n",
    "    # Extract the row corresponding to 'point'\n",
    "    num_pt = (dense_points.iloc[point].values)+1\n",
    "    \n",
    "    \n",
    "    # Calculate new coordinates\n",
    "    x_coord = x_origin + num_pt[0] * x_size\n",
    "    y_coord = y_origin + num_pt[1] * y_size\n",
    "    z_coord = z_origin + num_pt[2] * z_size\n",
    "    \n",
    "    return x_coord, y_coord, z_coord\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def extract_connectivity(xyz_df, threshhold_distance=1.82):\n",
    "    coordinates=np.array(xyz_df[['x','y','z']].values)\n",
    "    atoms_symbol=np.array(xyz_df['atom'].values)\n",
    "    # compute the pairwise distances between the points\n",
    "    distances = pdist(coordinates)\n",
    "    # convert the flat array of distances into a distance matrix\n",
    "    dist_matrix = squareform(distances)\n",
    "    dist_df=pd.DataFrame(dist_matrix).stack().reset_index()\n",
    "    dist_df.columns = ['a1', 'a2', 'value']\n",
    "    dist_df['first_atom']=[atoms_symbol[i] for i in dist_df['a1']]\n",
    "    dist_df['second_atom']=[atoms_symbol[i] for i in dist_df['a2']]\n",
    "    remove_list=[]\n",
    "    dist_array=np.array(dist_df)\n",
    "    remove_list = []\n",
    "    for idx, row in enumerate(dist_array):\n",
    "        remove_flag = False\n",
    "      \n",
    "        if row[0] == row[1]:\n",
    "            remove_flag = True\n",
    "          \n",
    "        if ((row[3] == 'H') & (row[4] not in help_functions.XYZConstants.NOF_ATOMS.value)):\n",
    "            remove_flag = True\n",
    "           \n",
    "        if ((row[3] == 'H') & (row[4] == 'H')):\n",
    "            remove_flag = True\n",
    "          \n",
    "        if (((row[3] == 'H') | (row[4] == 'H')) & (row[2] >= 1.5)):\n",
    "            remove_flag = True\n",
    "           \n",
    "        if ((row[2] >= threshhold_distance) | (row[2] == 0)):\n",
    "            remove_flag = True\n",
    "      \n",
    "\n",
    "        if remove_flag:\n",
    "            remove_list.append(idx)\n",
    "\n",
    "    dist_df=dist_df.drop(remove_list)\n",
    "    dist_df[['min_col', 'max_col']] = pd.DataFrame(np.sort(dist_df[['a1', 'a2']], axis=1), index=dist_df.index)\n",
    "    dist_df = dist_df.drop(columns=['a1', 'a2']).rename(columns={'min_col': 0, 'max_col': 1})\n",
    "    dist_df = dist_df.drop_duplicates(subset=[0, 1])\n",
    "    return pd.DataFrame(dist_df[[0,1]]+1)\n",
    "\n",
    "def direction_atoms_for_sterimol(bonds_df,base_atoms)->list: #help function for sterinol\n",
    "    \"\"\"\n",
    "    a function that return the base atom indices for coordination transformation according to the bonded atoms.\n",
    "    you can insert two atom indicess-[1,2] output [1,2,8] or the second bonded atom\n",
    "    if the first one repeats-[1,2,1] output [1,2,3]\n",
    "    \"\"\"\n",
    "    \n",
    "    base_atoms_copy=base_atoms[0:2]\n",
    "    origin,direction=base_atoms[0],base_atoms[1]\n",
    "    bonds_df = bonds_df[~((bonds_df[0] == origin) & (bonds_df[1] == direction)) & \n",
    "                              ~((bonds_df[0] == direction) & (bonds_df[1] == origin))]\n",
    "    \n",
    "    try :\n",
    "        base_atoms[2]==origin\n",
    "        if(any(bonds_df[0]==direction)):\n",
    "            # take the second atom in the bond where the first equeal to the direction, second option\n",
    "            base_atoms_copy[2]=int(bonds_df[(bonds_df[0]==direction)][1].iloc[1])\n",
    "        else:\n",
    "            # take the first atom in the bond where the first equeal to the direction, second option\n",
    "            base_atoms_copy[2]=int(bonds_df[(bonds_df[1]==direction)][0].iloc[1])\n",
    "    except: \n",
    "        \n",
    "        for _, row in bonds_df.iterrows():\n",
    "            if row[0] == direction:\n",
    "                base_atoms_copy.append(row[1])\n",
    "                break\n",
    "            elif row[1] == direction:\n",
    "                base_atoms_copy.append(row[0])\n",
    "                break\n",
    "    return base_atoms_copy\n",
    "\n",
    "from utils import help_functions\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "\n",
    "def get_molecule_connections(bonds_df,source,direction):\n",
    "    graph=ig.Graph.DataFrame(edges=bonds_df,directed=True)\n",
    "    paths=graph.get_all_simple_paths(v=source,mode='all')\n",
    "    with_direction=[path for path in paths if (direction in path)]\n",
    "    longest_path=np.unique(help_functions.flatten_list(with_direction))\n",
    "    return longest_path\n",
    "\n",
    "def calc_new_base_atoms(coordinates_array, atom_indices):  #help function for calc_coordinates_transformation\n",
    "    \"\"\"\n",
    "    a function that calculates the new base atoms for the transformation of the coordinates.\n",
    "    optional: if the atom_indices is 4, the origin will be the middle of the first two atoms.\n",
    "    \"\"\"\n",
    "    new_origin=coordinates_array[atom_indices[0], 0:3]\n",
    "    \n",
    "    if (len(atom_indices)==4):\n",
    "        new_origin=(new_origin+coordinates_array[atom_indices[1]])/2\n",
    "    new_y=(coordinates_array[atom_indices[-2]]-new_origin)/np.linalg.norm((coordinates_array[atom_indices[-2]]-new_origin))\n",
    "    coplane=((coordinates_array[atom_indices[-1]]-new_origin)/np.linalg.norm((coordinates_array[atom_indices[-1]]-new_origin)+0.00000001))\n",
    "    return (new_origin,new_y,coplane)\n",
    "\n",
    "def np_cross_and_vstack(plane_1, plane_2):\n",
    "    cross_plane=np.cross(plane_1, plane_2)\n",
    "    united_results=np.vstack([plane_1, plane_2, cross_plane])\n",
    "    return united_results\n",
    "\n",
    "\n",
    "def transform_row(row_array, new_basis, new_origin, round_digits):\n",
    "    translocated_row = row_array - new_origin\n",
    "    return np.dot(new_basis, translocated_row).round(round_digits)\n",
    "\n",
    "def mag(x):\n",
    "    return np.linalg.norm(x, axis=1)\n",
    "\n",
    "def mag_2d(x):\n",
    "    return np.sqrt(x[0] ** 2 + x[2] ** 2)\n",
    "    \n",
    "\n",
    "def close_atom(dens_pt, trans_co, n_atoms):\n",
    "    # Calculate vector differences\n",
    "    differences = trans_co[dens_pt, :3] - trans_co[:n_atoms, :3]\n",
    "    # Apply the magnitude function\n",
    "    distances = mag(differences)\n",
    "    # Return the index of the minimum distance (1-based index)\n",
    "    return np.argmin(distances) + 1\n",
    "\n",
    "ATOMIC_NUMBERS ={\n",
    "    '1':'H', '5':'B', '6':'C', '7':'N', '8':'O', '9':'F', '14':'Si',\n",
    "             '15':'P', '16':'S', '17':'Cl', '35':'Br', '53':'I', '27':'Co', '28':'Ni'}\n",
    "\n",
    "\n",
    "class cube():\n",
    "\n",
    "    def __init__(self, fname=None, base_atoms=[1,2]):\n",
    "        self.fname=fname\n",
    "        self.base_atoms=base_atoms\n",
    "        self.xyz_from_cube()\n",
    "        self.process_cube_data()\n",
    "        \n",
    "    def xyz_from_cube(self):\n",
    "        # Remove the existing .xyz file if it exists\n",
    "        xyz_file_path = os.path.splitext(self.fname)[0] + \".xyz\"\n",
    "        if os.path.exists(xyz_file_path):\n",
    "            os.unlink(xyz_file_path)\n",
    "\n",
    "        # Read data from the cube file\n",
    "        with open(self.fname, 'r') as file:\n",
    "            self.cube_data = file.readlines()\n",
    "\n",
    "        # Processing the header and extracting the number of atoms\n",
    "        self.n_atoms = int(self.cube_data[2].split()[0])\n",
    "        atom_data = self.cube_data[6:6 + self.n_atoms]\n",
    "\n",
    "        # Creating a DataFrame from the atom data\n",
    "        \n",
    "        atoms = []\n",
    "        for line in atom_data:\n",
    "            parts = line.split()\n",
    "            atom_type = int(parts[0])  # Assuming the atomic number is given\n",
    "            x, y, z = float(parts[2]), float(parts[3]), float(parts[4])\n",
    "            # Convert from Bohr to Angstrom\n",
    "            atoms.append([atom_type, x * 0.529177249, y * 0.529177249, z * 0.529177249])\n",
    "            # atoms_reg.append([atom_type, x , y , z ])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(atoms, columns=['atom', 'x', 'y', 'z'])\n",
    "        atoms=df['atom'].astype(str).map(ATOMIC_NUMBERS)\n",
    "        df['atom']=atoms\n",
    "        self.xyz_df=df\n",
    "        return None\n",
    "    \n",
    "    def process_cube_data_to_array(self):\n",
    "        # Determine the maximum length of rows\n",
    "        max_length = max(len(row) for row in self.cube_data)\n",
    "\n",
    "        # Pad rows with NaN to make them all the same length\n",
    "        padded_data = []\n",
    "        for row in self.cube_data[2:]:\n",
    "            float_row = [float(x) for x in row.split()]\n",
    "            # if len(float_row) < max_length:\n",
    "            #     float_row.extend([np.nan] * (max_length - len(float_row)))\n",
    "            padded_data.append(float_row)\n",
    "\n",
    "        # Convert the padded data to a numpy array\n",
    "        array_data = np.array(padded_data)\n",
    "        return array_data\n",
    "\n",
    "    def pad_cube_data(self,data, max_length):\n",
    "        processed_data = []\n",
    "        for line in data:\n",
    "            float_values = list(map(float, line.split()))\n",
    "            # Pad the row with NaN to ensure it has exactly 6 columns\n",
    "            while len(float_values) < max_length:\n",
    "                float_values.append(np.nan)\n",
    "            processed_data.append(float_values)\n",
    "        return pd.DataFrame(processed_data)\n",
    "\n",
    "    def process_cube_data(self,isovalue=0.003):\n",
    "\n",
    "        self.structure = [self.cube_data[2:][i] for i in range(4 + self.n_atoms)]\n",
    "        self.density=self.cube_data[(6 + self.n_atoms):]\n",
    "        self.structure_df=self.pad_cube_data(self.structure, 5)\n",
    "        self.density_df=self.pad_cube_data(self.density, 6)\n",
    "        x_origin, y_origin, z_origin = self.structure_df.iloc[0,1], self.structure_df.iloc[0,2], self.structure_df.iloc[0,3]\n",
    "        x_step, y_step, z_step = self.structure_df.iloc[1,0], self.structure_df.iloc[2,0], self.structure_df.iloc[3,0]\n",
    "        x_size, y_size, z_size = self.structure_df.iloc[1,1], self.structure_df.iloc[2,2], self.structure_df.iloc[3,3]\n",
    "\n",
    "        bonds_df=extract_connectivity(self.xyz_df)\n",
    "        rows_per_block = int(np.ceil(z_step / 6)) + 1 # 12\n",
    "        target_length = int(np.ceil(cbrt(x_step * y_step * z_step)))-1 # 80\n",
    "        blocks = list(range(0, len(self.density_df) , rows_per_block-1))\n",
    "        self.density_df=self.density_df.fillna(0)\n",
    "        row_dens_data = [vec_organizer(block, self.density_df, blocks, x_step, y_step, z_step) for block in range(len(blocks))]\n",
    "\n",
    "        row_dens_df=pd.DataFrame()\n",
    "        for i in range(target_length):\n",
    "            row=[]\n",
    "            for j in range(len(blocks)):\n",
    "                row.append(row_dens_data[j][i])\n",
    "            row_dens_df[i]=row\n",
    "        row_dens_df[(row_dens_df > isovalue * 1.1) | (row_dens_df < isovalue)] = 0\n",
    "        \n",
    "        x_blocks = []\n",
    "        for i in range(0, len(row_dens_df), int(y_step)):\n",
    "            x_blocks.append(row_dens_df.iloc[i:i+int(y_step)])\n",
    "        # x_blocks_df = pd.concat(x_blocks, axis=1)\n",
    "        non_zero_regions = [index for index, df in enumerate(x_blocks) if df.sum().sum() != 0]\n",
    "   \n",
    "        dense_points=pt_space_block_binder(non_zero_regions, x_blocks)\n",
    "        x=[]\n",
    "        y=[]\n",
    "        z=[]\n",
    "        for point in range(len(dense_points)):\n",
    "            x_coord, y_coord, z_coord = dens_to_pt(point, dense_points, x_origin, y_origin, z_origin, x_size, y_size, z_size)\n",
    "            x.append(x_coord)\n",
    "            y.append(y_coord)\n",
    "            z.append(z_coord)\n",
    "        coordinates_space_df=pd.DataFrame({'x':x,'y':y,'z':z})\n",
    "        df=self.xyz_df[['x','y','z']]/0.529177249\n",
    "        xyz=pd.concat([df,coordinates_space_df]).reset_index(drop=True)\n",
    "    \n",
    "        base_atoms=np.array(direction_atoms_for_sterimol(bonds_df,self.base_atoms))-1\n",
    "        tag=None\n",
    "        \n",
    "        if count_0(xyz.iloc[:self.n_atoms, :3].sum()) >= 2:\n",
    "            \n",
    "            col_1 = count_0(xyz.iloc[:, 0])\n",
    "            col_2 = count_0(xyz.iloc[:, 1])\n",
    "            col_3 = count_0(xyz.iloc[:, 2])\n",
    "            # Find the column with the maximum count of leading zeros\n",
    "            place_num = np.argmax([col_1, col_2, col_3]) + 1  # +1 because Python uses zero-based indexing\n",
    "            # Create a new row where the max place is 1 and others are 0\n",
    "            new_row = pd.DataFrame([[0, 0, 0]], columns=xyz.columns)\n",
    "            new_row.iloc[0, place_num - 1] = 1  # -1 to adjust for zero-based index\n",
    "            # Insert the new row at position n_atoms\n",
    "            xyz = pd.concat([xyz.iloc[:self.n_atoms], new_row, xyz.iloc[self.n_atoms:]]).reset_index(drop=True)\n",
    "            # Suppose numeric_atoms is a list that holds some values where the 3rd element is to be updated\n",
    "            numeric_atoms = [None, None, None]  # Example initialization\n",
    "            numeric_atoms[2] = self.n_atoms + 1  # Update the third element\n",
    "            tag = 1  # Set tag to 1 as per the R script logic\n",
    " \n",
    "        new_origin,new_y,coplane=calc_new_base_atoms(xyz.values,base_atoms)\n",
    "        cross_y_coplane=np.cross(coplane,new_y)\n",
    "        coef_mat=np.stack([new_y,coplane,cross_y_coplane])\n",
    "        angle_new_y_coplane=calc_angle(coplane,new_y)\n",
    "        cop_ang_x=angle_new_y_coplane-(np.pi/2)\n",
    "        result_vector=[0,np.cos(cop_ang_x),0]\n",
    "        #result_vector=[np.cos(cop_ang_x), 0, 0]\n",
    "        new_x,_,_,_=np.linalg.lstsq(coef_mat,result_vector,rcond=None)\n",
    "        new_basis=np_cross_and_vstack(new_x, new_y)\n",
    "        coordinates_array=xyz.values\n",
    "        transformed_coordinates = np.apply_along_axis(lambda x: transform_row(x, new_basis, new_origin, 6), 1,\n",
    "                                                  coordinates_array)\n",
    "        nan_atoms=[np.nan]*self.n_atoms\n",
    "        close_atoms=[]\n",
    "        for i in range(self.n_atoms , len(transformed_coordinates)):\n",
    "            close_atoms.append(close_atom(i, transformed_coordinates, self.n_atoms))\n",
    "        ## add a column to the transformed coordinates of close atoms, put Nan in length of the original atoms first\n",
    "        close_atoms=nan_atoms+close_atoms\n",
    "        ## add the close atoms to the transformed coordinates\n",
    "        transformed_coordinates=np.column_stack([transformed_coordinates,close_atoms])\n",
    "        rlev=get_molecule_connections(bonds_df,self.base_atoms[0],self.base_atoms[1])\n",
    "        filtered_indices = np.isin(transformed_coordinates[:, 3], rlev)\n",
    "        tcs = transformed_coordinates[filtered_indices, :3]\n",
    "        ## now make rest_tcs from the rest of the transformed coordinates\n",
    "        rest_tcs = transformed_coordinates[~filtered_indices, :3]\n",
    "        \n",
    "        mutate=[mag_2d(tcs[i])*0.529177249 for i in range(len(tcs))]\n",
    "        tcs=np.column_stack([tcs,mutate])\n",
    "        L=max(tcs[:,1]) * 0.529177249\n",
    "        B5=max(tcs[:,3])\n",
    "        # make plane variable form column 0 and 2\n",
    "        plane=tcs[:,[0,2]]\n",
    "        df=pd.DataFrame(columns=['b1', 'b1_loc', 'x_b1', 'z_b1'])\n",
    "        for i in range(1,91):\n",
    "            tc_plane=get_transfomed_plane_for_sterimol(plane,i)\n",
    "            avs=np.abs([max(tc_plane[:,0]),min(tc_plane[:,0]), \n",
    "                    max(tc_plane[:,1]),min(tc_plane[:,1])])\n",
    "            \n",
    "            tc_plane=tc_plane.round(3)\n",
    "            if np.where(avs==avs.min())[0][0] in [0,1]:\n",
    "\n",
    "                idx=np.where(np.isclose(np.abs(tc_plane[:,0]),(avs.min()).round(3)))[0][0]\n",
    "                value_from_tcs = tcs[idx, 1]\n",
    "                B1_loc=  value_from_tcs * 0.529177249\n",
    "                x_b1 = tcs[idx, 0]\n",
    "                z_b1 = tcs[idx, 2]\n",
    "            elif np.where(avs==avs.min())[0][0] in [2,3]:\n",
    "\n",
    "                idx=np.where(np.isclose(np.abs(tc_plane[:,1]),(avs.min()).round(3)))[0][0]\n",
    "                value_from_tcs = tcs[idx, 1]\n",
    "                B1_loc=  value_from_tcs * 0.529177249\n",
    "                x_b1 = tcs[idx, 0]\n",
    "                z_b1 = tcs[idx, 2]\n",
    "            b1=np.abs(min(avs))* 0.529177249\n",
    "            b_df=pd.DataFrame({'b1': b1, 'b1_loc': B1_loc, 'x_b1': x_b1, 'z_b1': z_b1}, index=[0])\n",
    "            df=pd.concat([df,b_df])\n",
    "\n",
    "        df=df.reset_index(drop=True)\n",
    "        B1=df['b1'].min()\n",
    "        x_b1=df['x_b1'].iloc[df['b1'].idxmin()]\n",
    "        z_b1=df['z_b1'].iloc[df['b1'].idxmin()]\n",
    "        loc_b1=df['b1_loc'].iloc[df['b1'].idxmin()]\n",
    "        loc_b5=tcs[np.argmax(tcs[:,3]),1]*0.529177249\n",
    "        sterimol_df=pd.DataFrame({'B1': B1, 'B5': B5, 'L': L,'loc_b5': loc_b5 ,'loc_b1': loc_b1}, index=[0])     \n",
    "               \n",
    "        return sterimol_df\n",
    "            # b1s.append(np.unique(np.vstack(B1)).max())####check\n",
    "            # b1s_loc.append(np.unique(np.vstack(B1_loc)).max())\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         B1        B5         L    loc_b5    loc_b1\n",
      "0  3.152309  3.772945  6.582881  4.096577  0.246048\n",
      "0    2.262742\n",
      "1    2.086739\n",
      "2    2.086739\n",
      "3    2.086739\n",
      "4    3.863265\n",
      "Name: b1_loc, dtype: float64\n",
      "0    3.230627\n",
      "1    3.223219\n",
      "2    3.215810\n",
      "3    3.207343\n",
      "4    3.216339\n",
      "Name: b1, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edens\\AppData\\Local\\Temp\\ipykernel_5392\\3549991389.py:548: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df=pd.concat([df,b_df])\n"
     ]
    }
   ],
   "source": [
    "x=cube(\"Ad_1_a.cube\",base_atoms=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
